{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import unicodedata\n",
    "import re\n",
    "import numpy as np\n",
    "import os\n",
    "import io\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from http://storage.googleapis.com/download.tensorflow.org/data/spa-eng.zip\n",
      "2646016/2638744 [==============================] - 3s 1us/step\n"
     ]
    }
   ],
   "source": [
    "# Download the file\n",
    "path_to_zip = tf.keras.utils.get_file(\n",
    "    'spa-eng.zip', origin='http://storage.googleapis.com/download.tensorflow.org/data/spa-eng.zip',\n",
    "    extract=True)\n",
    "\n",
    "path_to_file = os.path.dirname(path_to_zip)+\"/spa-eng/spa.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95171 95171 23793 23793\n"
     ]
    }
   ],
   "source": [
    "# Converts the unicode file to ascii\n",
    "def unicode_to_ascii(s):\n",
    "    return ''.join(c for c in unicodedata.normalize('NFD', s)\n",
    "        if unicodedata.category(c) != 'Mn')\n",
    "\n",
    "\n",
    "def preprocess_sentence(w):\n",
    "    w = unicode_to_ascii(w.lower().strip())\n",
    "\n",
    "    # creating a space between a word and the punctuation following it\n",
    "    # eg: \"he is a boy.\" => \"he is a boy .\"\n",
    "    # Reference:- https://stackoverflow.com/questions/3645931/python-padding-punctuation-with-white-spaces-keeping-punctuation\n",
    "    w = re.sub(r\"([?.!,¿])\", r\" \\1 \", w)\n",
    "    w = re.sub(r'[\" \"]+', \" \", w)\n",
    "\n",
    "    # replacing everything with space except (a-z, A-Z, \".\", \"?\", \"!\", \",\")\n",
    "    w = re.sub(r\"[^a-zA-Z?.!,¿]+\", \" \", w)\n",
    "\n",
    "    w = w.rstrip().strip()\n",
    "\n",
    "    # adding a start and an end token to the sentence\n",
    "    # so that the model know when to start and stop predicting.\n",
    "    w = '<start> ' + w + ' <end>'\n",
    "    return w\n",
    "\n",
    "\n",
    "# 1. Remove the accents\n",
    "# 2. Clean the sentences\n",
    "# 3. Return word pairs in the format: [ENGLISH, SPANISH]\n",
    "def create_dataset(path, num_examples):\n",
    "    lines = io.open(path, encoding='UTF-8').read().strip().split('\\n')\n",
    "    word_pairs = [[preprocess_sentence(w) for w in l.split('\\t')]  for l in lines[:num_examples]]\n",
    "    return zip(*word_pairs)\n",
    "\n",
    "def max_length(tensor):\n",
    "    return max(len(t) for t in tensor)\n",
    "\n",
    "def tokenize(lang):\n",
    "    lang_tokenizer = tf.keras.preprocessing.text.Tokenizer(\n",
    "      filters='')\n",
    "    lang_tokenizer.fit_on_texts(lang)\n",
    "\n",
    "    tensor = lang_tokenizer.texts_to_sequences(lang)\n",
    "    tensor = tf.keras.preprocessing.sequence.pad_sequences(tensor, padding='post')\n",
    "    return tensor, lang_tokenizer\n",
    "\n",
    "def load_dataset(path, num_examples=None):\n",
    "    # creating cleaned input, output pairs\n",
    "    targ_lang, inp_lang = create_dataset(path, num_examples)\n",
    "\n",
    "    input_tensor, inp_lang_tokenizer = tokenize(inp_lang)\n",
    "    target_tensor, targ_lang_tokenizer = tokenize(targ_lang)\n",
    "\n",
    "    return input_tensor, target_tensor, inp_lang_tokenizer, targ_lang_tokenizer\n",
    "\n",
    "\n",
    "# Try experimenting with the size of that dataset\n",
    "num_examples = None  #30000\n",
    "input_tensor, target_tensor, inp_lang, targ_lang = load_dataset(path_to_file, num_examples)\n",
    "\n",
    "# Calculate max_length of the target tensors\n",
    "max_length_targ, max_length_inp = max_length(target_tensor), max_length(input_tensor)\n",
    "max_length_targ = max(max_length_targ, max_length_inp)\n",
    "max_length_inp = max_length_targ\n",
    "\n",
    "# Creating training and validation sets using an 80-20 split\n",
    "input_tensor_train, input_tensor_val, target_tensor_train, target_tensor_val = train_test_split(input_tensor, target_tensor, test_size=0.2)\n",
    "\n",
    "# Show length\n",
    "print(len(input_tensor_train), len(target_tensor_train), len(input_tensor_val), len(target_tensor_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_dim, enc_units, batch_sz):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.batch_sz = batch_sz\n",
    "        self.enc_units = enc_units\n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "        self.gru = tf.keras.layers.GRU(self.enc_units,\n",
    "                                       return_sequences=True,\n",
    "                                       return_state=True,\n",
    "                                       recurrent_initializer='glorot_uniform')\n",
    "\n",
    "    def call(self, x, hidden):\n",
    "        x = self.embedding(x)\n",
    "        output, state = self.gru(x, initial_state = hidden)\n",
    "        return output, state\n",
    "\n",
    "    def initialize_hidden_state(self):\n",
    "        return tf.zeros((self.batch_sz, self.enc_units))\n",
    "    \n",
    "    \n",
    "class BahdanauAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self, units):\n",
    "        super(BahdanauAttention, self).__init__()\n",
    "        self.W1 = tf.keras.layers.Dense(units)\n",
    "        self.W2 = tf.keras.layers.Dense(units)\n",
    "        self.V = tf.keras.layers.Dense(1)\n",
    "\n",
    "    def call(self, query, values):\n",
    "        # hidden shape == (batch_size, hidden size)\n",
    "        # hidden_with_time_axis shape == (batch_size, 1, hidden size)\n",
    "        # we are doing this to perform addition to calculate the score\n",
    "        hidden_with_time_axis = tf.expand_dims(query, 1)\n",
    "\n",
    "        # score shape == (batch_size, max_length, 1)\n",
    "        # we get 1 at the last axis because we are applying score to self.V\n",
    "        # the shape of the tensor before applying self.V is (batch_size, max_length, units)\n",
    "        score = self.V(tf.nn.tanh(\n",
    "            self.W1(values) + self.W2(hidden_with_time_axis)))\n",
    "\n",
    "        # attention_weights shape == (batch_size, max_length, 1)\n",
    "        attention_weights = tf.nn.softmax(score, axis=1)\n",
    "\n",
    "        # context_vector shape after sum == (batch_size, hidden_size)\n",
    "        context_vector = attention_weights * values\n",
    "        context_vector = tf.reduce_sum(context_vector, axis=1)\n",
    "\n",
    "        return context_vector, attention_weights\n",
    "    \n",
    "    \n",
    "class Decoder(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_dim, dec_units, batch_sz):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.batch_sz = batch_sz\n",
    "        self.dec_units = dec_units\n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "        self.gru = tf.keras.layers.GRU(self.dec_units,\n",
    "                                       return_sequences=True,\n",
    "                                       return_state=True,\n",
    "                                       recurrent_initializer='glorot_uniform')\n",
    "        self.fc = tf.keras.layers.Dense(vocab_size)\n",
    "\n",
    "        # used for attention\n",
    "        self.attention = BahdanauAttention(self.dec_units)\n",
    "\n",
    "    def call(self, x, hidden, enc_output):\n",
    "        # enc_output shape == (batch_size, max_length, hidden_size)\n",
    "        context_vector, attention_weights = self.attention(hidden, enc_output)\n",
    "\n",
    "        # x shape after passing through embedding == (batch_size, 1, embedding_dim)\n",
    "        x = self.embedding(x)\n",
    "\n",
    "        # x shape after concatenation == (batch_size, 1, embedding_dim + hidden_size)\n",
    "        x = tf.concat([tf.expand_dims(context_vector, 1), x], axis=-1)\n",
    "\n",
    "        # passing the concatenated vector to the GRU\n",
    "        output, state = self.gru(x)\n",
    "\n",
    "        # output shape == (batch_size * 1, hidden_size)\n",
    "        output = tf.reshape(output, (-1, output.shape[2]))\n",
    "\n",
    "        # output shape == (batch_size, vocab)\n",
    "        x = self.fc(output)\n",
    "\n",
    "        return x, state, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "BUFFER_SIZE = len(input_tensor_train)\n",
    "BATCH_SIZE = 32\n",
    "steps_per_epoch = len(input_tensor_train)//BATCH_SIZE\n",
    "embedding_dim = 256\n",
    "units = 1024\n",
    "vocab_inp_size = len(inp_lang.word_index)+1\n",
    "vocab_tar_size = len(targ_lang.word_index)+1\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices((input_tensor_train, target_tensor_train))\\\n",
    "    .shuffle(BUFFER_SIZE)\\\n",
    "    .batch(BATCH_SIZE, drop_remainder=True)\n",
    "\n",
    "# components\n",
    "encoder = Encoder(vocab_inp_size, embedding_dim, units, BATCH_SIZE)\n",
    "attention_layer = BahdanauAttention(10)\n",
    "decoder = Decoder(vocab_tar_size, embedding_dim, units, BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset\n",
    "example_input_batch, example_target_batch = next(iter(dataset))\n",
    "print ('Input batch shape (batch size, len)', example_input_batch.shape)\n",
    "print ('Input batch shape (batch size, len)', example_target_batch.shape)\n",
    "\n",
    "# sample input\n",
    "sample_hidden = encoder.initialize_hidden_state()\n",
    "sample_output, sample_hidden = encoder(example_input_batch, sample_hidden)\n",
    "print ('Encoder output shape: (batch size, sequence length, units) {}'.format(sample_output.shape))\n",
    "print ('Encoder Hidden state shape: (batch size, units) {}'.format(sample_hidden.shape))\n",
    "\n",
    "# sample attention\n",
    "attention_result, attention_weights = attention_layer(sample_hidden, sample_output)\n",
    "print(\"Attention result shape: (batch size, units) {}\".format(attention_result.shape))\n",
    "print(\"Attention weights shape: (batch_size, sequence_length, 1) {}\".format(attention_weights.shape))\n",
    "\n",
    "# sample output\n",
    "sample_decoder_output, sample_decoder_state, _ = decoder(tf.random.uniform((BATCH_SIZE, 1)),\n",
    "                                                         sample_hidden, sample_output)\n",
    "print ('Decoder output shape: (batch_size, vocab size) {}'.format(sample_decoder_output.shape))\n",
    "print ('Decoder state shape: (batch_size, vocab size) {}'.format(sample_decoder_state.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam()\n",
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "    from_logits=True, reduction='none')\n",
    "\n",
    "def loss_function(real, pred):\n",
    "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "    loss_ = loss_object(real, pred)\n",
    "\n",
    "    mask = tf.cast(mask, dtype=loss_.dtype)\n",
    "    loss_ *= mask\n",
    "\n",
    "    return tf.reduce_mean(loss_)\n",
    "\n",
    "checkpoint_dir = './seq2seq_training_checkpoints'\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
    "checkpoint = tf.train.Checkpoint(optimizer=optimizer,\n",
    "                                 encoder=encoder,\n",
    "                                 decoder=decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.config.experimental.list_physical_devices(device_type=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"add_49:0\", shape=(), dtype=float32)\n",
      "[<tf.Variable 'encoder/embedding/embeddings:0' shape=(24794, 256) dtype=float32>, <tf.Variable 'encoder/gru/kernel:0' shape=(256, 3072) dtype=float32>, <tf.Variable 'encoder/gru/recurrent_kernel:0' shape=(1024, 3072) dtype=float32>, <tf.Variable 'encoder/gru/bias:0' shape=(2, 3072) dtype=float32>, <tf.Variable 'decoder/embedding_1/embeddings:0' shape=(12934, 256) dtype=float32>, <tf.Variable 'decoder/gru_1/kernel:0' shape=(1280, 3072) dtype=float32>, <tf.Variable 'decoder/gru_1/recurrent_kernel:0' shape=(1024, 3072) dtype=float32>, <tf.Variable 'decoder/gru_1/bias:0' shape=(2, 3072) dtype=float32>, <tf.Variable 'decoder/dense_3/kernel:0' shape=(1024, 12934) dtype=float32>, <tf.Variable 'decoder/dense_3/bias:0' shape=(12934,) dtype=float32>, <tf.Variable 'decoder/bahdanau_attention_1/dense_4/kernel:0' shape=(1024, 1024) dtype=float32>, <tf.Variable 'decoder/bahdanau_attention_1/dense_4/bias:0' shape=(1024,) dtype=float32>, <tf.Variable 'decoder/bahdanau_attention_1/dense_5/kernel:0' shape=(1024, 1024) dtype=float32>, <tf.Variable 'decoder/bahdanau_attention_1/dense_5/bias:0' shape=(1024,) dtype=float32>, <tf.Variable 'decoder/bahdanau_attention_1/dense_6/kernel:0' shape=(1024, 1) dtype=float32>, <tf.Variable 'decoder/bahdanau_attention_1/dense_6/bias:0' shape=(1,) dtype=float32>]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m~usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py\u001b[0m in \u001b[0;36mget_attr\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   2382\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mc_api_util\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtf_buffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mbuf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2383\u001b[0;31m         \u001b[0mc_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_OperationGetAttrValueProto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_c_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2384\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mc_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Operation 'while' has no attr named '_XlaCompile'.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m~usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/gradients_util.py\u001b[0m in \u001b[0;36m_MaybeCompile\u001b[0;34m(scope, op, func, grad_fn)\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m       \u001b[0mxla_compile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_attr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"_XlaCompile\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m       xla_separate_compiled_gradients = op.get_attr(\n",
      "\u001b[0;32m~usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py\u001b[0m in \u001b[0;36mget_attr\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   2386\u001b[0m       \u001b[0;31m# Convert to ValueError for backwards compatibility.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2387\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2388\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattr_value_pb2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAttrValue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Operation 'while' has no attr named '_XlaCompile'.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m~usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py\u001b[0m in \u001b[0;36mget_attr\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   2382\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mc_api_util\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtf_buffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mbuf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2383\u001b[0;31m         \u001b[0mc_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_OperationGetAttrValueProto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_c_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2384\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mc_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Operation 'mul_2' has no attr named '_XlaCompile'.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m~usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/gradients_util.py\u001b[0m in \u001b[0;36m_MaybeCompile\u001b[0;34m(scope, op, func, grad_fn)\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m       \u001b[0mxla_compile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_attr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"_XlaCompile\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m       xla_separate_compiled_gradients = op.get_attr(\n",
      "\u001b[0;32m~usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py\u001b[0m in \u001b[0;36mget_attr\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   2386\u001b[0m       \u001b[0;31m# Convert to ValueError for backwards compatibility.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2387\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2388\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattr_value_pb2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAttrValue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Operation 'mul_2' has no attr named '_XlaCompile'.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-0e9e0659d9c5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBUFFER_SIZE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mbatch_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menc_hidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m             \u001b[0mtotal_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mbatch_loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_counter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcalled_without_tracing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    501\u001b[0m       \u001b[0;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    502\u001b[0m       \u001b[0minitializer_map\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobject_identity\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mObjectIdentityDictionary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 503\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializer_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    504\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    505\u001b[0m       \u001b[0;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    406\u001b[0m     self._concrete_stateful_fn = (\n\u001b[1;32m    407\u001b[0m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[0;32m--> 408\u001b[0;31m             *args, **kwds))\n\u001b[0m\u001b[1;32m    409\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    410\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minvalid_creator_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0munused_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0munused_kwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1846\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_signature\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1847\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1848\u001b[0;31m     \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1849\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1850\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   2148\u001b[0m         \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2149\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mgraph_function\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2150\u001b[0;31m           \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2151\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2152\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   2039\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2040\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2041\u001b[0;31m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[1;32m   2042\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2043\u001b[0m         \u001b[0;31m# Tell the ConcreteFunction to clean up its graph once it goes out of\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    913\u001b[0m                                           converted_func)\n\u001b[1;32m    914\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 915\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    356\u001b[0m         \u001b[0;31m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    357\u001b[0m         \u001b[0;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 358\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    359\u001b[0m     \u001b[0mweak_wrapped_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweakref\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mref\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapped_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    360\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    900\u001b[0m                     \u001b[0moptional_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mautograph_options\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    901\u001b[0m                     \u001b[0muser_requested\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 902\u001b[0;31m                 ), args, kwargs)\n\u001b[0m\u001b[1;32m    903\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    904\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mconverted_call\u001b[0;34m(f, options, args, kwargs, caller_fn_scope)\u001b[0m\n\u001b[1;32m    537\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    538\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 539\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconverted_f\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0meffective_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    540\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    541\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconverted_f\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0meffective_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~tmp/tmps5k3guhf.py\u001b[0m in \u001b[0;36mtf__train_step\u001b[0;34m(inp, targ, enc_hidden)\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvariables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m         \u001b[0mgradients\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_step_scope\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallopts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvariables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_step_scope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m         \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_gradients\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_step_scope\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallopts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_step_scope\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallopts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mgradients\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvariables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_step_scope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_step_scope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mconverted_call\u001b[0;34m(f, options, args, kwargs, caller_fn_scope)\u001b[0m\n\u001b[1;32m    437\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    438\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_requested\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mconversion\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_whitelisted_for_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 439\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_call_unconverted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    440\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    441\u001b[0m   \u001b[0;31m# internal_convert_user_code is for example turned off when issuing a dynamic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/impl/api.py\u001b[0m in \u001b[0;36m_call_unconverted\u001b[0;34m(f, args, kwargs, options, update_cache)\u001b[0m\n\u001b[1;32m    330\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 332\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    333\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m     \u001b[0m_attach_metadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/backprop.py\u001b[0m in \u001b[0;36mgradient\u001b[0;34m(self, target, sources, output_gradients, unconnected_gradients)\u001b[0m\n\u001b[1;32m   1012\u001b[0m         \u001b[0moutput_gradients\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_gradients\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1013\u001b[0m         \u001b[0msources_raw\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mflat_sources_raw\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1014\u001b[0;31m         unconnected_gradients=unconnected_gradients)\n\u001b[0m\u001b[1;32m   1015\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1016\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_persistent\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/imperative_grad.py\u001b[0m in \u001b[0;36mimperative_grad\u001b[0;34m(tape, target, sources, output_gradients, sources_raw, unconnected_gradients)\u001b[0m\n\u001b[1;32m     74\u001b[0m       \u001b[0moutput_gradients\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m       \u001b[0msources_raw\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m       compat.as_str(unconnected_gradients.value))\n\u001b[0m",
      "\u001b[0;32m~usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_backward_function\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m    736\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_backward_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    737\u001b[0m       \u001b[0mcall_op\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 738\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_rewrite_forward_and_call_backward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    739\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_backward_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_rewrite_forward_and_call_backward\u001b[0;34m(self, op, *doutputs)\u001b[0m\n\u001b[1;32m    659\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_rewrite_forward_and_call_backward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mdoutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    660\u001b[0m     \u001b[0;34m\"\"\"Add outputs to the forward call and feed them to the grad function.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 661\u001b[0;31m     \u001b[0mforward_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbackwards_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward_backward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    662\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mbackwards_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    663\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36mforward_backward\u001b[0;34m(self, num_doutputs)\u001b[0m\n\u001b[1;32m    580\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mforward_backward\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    581\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mforward_backward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 582\u001b[0;31m     \u001b[0mforward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbackward\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_construct_forward_backward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_doutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    583\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cached_function_pairs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnum_doutputs\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbackward\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    584\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbackward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_construct_forward_backward\u001b[0;34m(self, num_doutputs)\u001b[0m\n\u001b[1;32m    627\u001b[0m           \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    628\u001b[0m           \u001b[0msignature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 629\u001b[0;31m           func_graph=backwards_graph)\n\u001b[0m\u001b[1;32m    630\u001b[0m       \u001b[0mbackwards_graph_captures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbackwards_graph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexternal_captures\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    631\u001b[0m       captures_from_forward = [\n",
      "\u001b[0;32m~usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    913\u001b[0m                                           converted_func)\n\u001b[1;32m    914\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 915\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_backprop_function\u001b[0;34m(*grad_ys)\u001b[0m\n\u001b[1;32m    617\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_func_graph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    618\u001b[0m           \u001b[0mgrad_ys\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgrad_ys\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 619\u001b[0;31m           src_graph=self._func_graph)\n\u001b[0m\u001b[1;32m    620\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    621\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_func_graph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/gradients_util.py\u001b[0m in \u001b[0;36m_GradientsHelper\u001b[0;34m(ys, xs, grad_ys, name, colocate_gradients_with_ops, gate_gradients, aggregation_method, stop_gradients, unconnected_gradients, src_graph)\u001b[0m\n\u001b[1;32m    677\u001b[0m                 \u001b[0;31m# functions.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    678\u001b[0m                 in_grads = _MaybeCompile(grad_scope, op, func_call,\n\u001b[0;32m--> 679\u001b[0;31m                                          lambda: grad_fn(op, *out_grads))\n\u001b[0m\u001b[1;32m    680\u001b[0m               \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    681\u001b[0m                 \u001b[0;31m# For function call ops, we add a 'SymbolicGradient'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/gradients_util.py\u001b[0m in \u001b[0;36m_MaybeCompile\u001b[0;34m(scope, op, func, grad_fn)\u001b[0m\n\u001b[1;32m    348\u001b[0m       \u001b[0mxla_scope\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_attr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"_XlaScope\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 350\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mgrad_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Exit early\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    351\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    352\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mxla_compile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/gradients_util.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    677\u001b[0m                 \u001b[0;31m# functions.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    678\u001b[0m                 in_grads = _MaybeCompile(grad_scope, op, func_call,\n\u001b[0;32m--> 679\u001b[0;31m                                          lambda: grad_fn(op, *out_grads))\n\u001b[0m\u001b[1;32m    680\u001b[0m               \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    681\u001b[0m                 \u001b[0;31m# For function call ops, we add a 'SymbolicGradient'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/while_v2.py\u001b[0m in \u001b[0;36m_WhileGrad\u001b[0;34m(op, *grads)\u001b[0m\n\u001b[1;32m    362\u001b[0m   body_grad_graph, args = _create_grad_func(\n\u001b[1;32m    363\u001b[0m       \u001b[0mys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_none_grads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcond_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbody_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 364\u001b[0;31m       util.unique_grad_fn_name(body_graph.name), op, maximum_iterations)\n\u001b[0m\u001b[1;32m    365\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    366\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mbody_grad_graph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhile_op_needs_rewrite\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/while_v2.py\u001b[0m in \u001b[0;36m_create_grad_func\u001b[0;34m(ys, xs, grads, cond_graph, body_graph, name, while_op, maximum_iterations)\u001b[0m\n\u001b[1;32m    605\u001b[0m       func_graph=_WhileBodyGradFuncGraph(name, cond_graph, body_graph,\n\u001b[1;32m    606\u001b[0m                                          \u001b[0mmaximum_iterations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwhile_op\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 607\u001b[0;31m                                          body_graph_inputs, body_graph_outputs))\n\u001b[0m\u001b[1;32m    608\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    609\u001b[0m   \u001b[0;31m# Update the list of outputs with tensors corresponding to the captured\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    913\u001b[0m                                           converted_func)\n\u001b[1;32m    914\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 915\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/while_v2.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m    601\u001b[0m   grad_func_graph = func_graph_module.func_graph_from_py_func(\n\u001b[1;32m    602\u001b[0m       \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 603\u001b[0;31m       \u001b[0;32mlambda\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0m_grad_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbody_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    604\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    605\u001b[0m       func_graph=_WhileBodyGradFuncGraph(name, cond_graph, body_graph,\n",
      "\u001b[0;32m~usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/while_v2.py\u001b[0m in \u001b[0;36m_grad_fn\u001b[0;34m(ys, xs, args, func_graph)\u001b[0m\n\u001b[1;32m    661\u001b[0m   grad_outs = gradients_util._GradientsHelper(\n\u001b[1;32m    662\u001b[0m       \u001b[0mys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_ys\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgrad_ys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunc_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 663\u001b[0;31m       unconnected_gradients=\"zero\")\n\u001b[0m\u001b[1;32m    664\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    665\u001b[0m   \u001b[0;31m# TODO(b/118712257): Handle the case when grad_outs has None's e.g. when there\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/gradients_util.py\u001b[0m in \u001b[0;36m_GradientsHelper\u001b[0;34m(ys, xs, grad_ys, name, colocate_gradients_with_ops, gate_gradients, aggregation_method, stop_gradients, unconnected_gradients, src_graph)\u001b[0m\n\u001b[1;32m    677\u001b[0m                 \u001b[0;31m# functions.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    678\u001b[0m                 in_grads = _MaybeCompile(grad_scope, op, func_call,\n\u001b[0;32m--> 679\u001b[0;31m                                          lambda: grad_fn(op, *out_grads))\n\u001b[0m\u001b[1;32m    680\u001b[0m               \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    681\u001b[0m                 \u001b[0;31m# For function call ops, we add a 'SymbolicGradient'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/gradients_util.py\u001b[0m in \u001b[0;36m_MaybeCompile\u001b[0;34m(scope, op, func, grad_fn)\u001b[0m\n\u001b[1;32m    348\u001b[0m       \u001b[0mxla_scope\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_attr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"_XlaScope\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 350\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mgrad_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Exit early\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    351\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    352\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mxla_compile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/gradients_util.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    677\u001b[0m                 \u001b[0;31m# functions.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    678\u001b[0m                 in_grads = _MaybeCompile(grad_scope, op, func_call,\n\u001b[0;32m--> 679\u001b[0;31m                                          lambda: grad_fn(op, *out_grads))\n\u001b[0m\u001b[1;32m    680\u001b[0m               \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    681\u001b[0m                 \u001b[0;31m# For function call ops, we add a 'SymbolicGradient'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py\u001b[0m in \u001b[0;36m_MulGrad\u001b[0;34m(op, grad)\u001b[0m\n\u001b[1;32m   1175\u001b[0m       \u001b[0m_ShapesFullySpecifiedAndEqual\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1176\u001b[0m       grad.dtype in (dtypes.int32, dtypes.float32)):\n\u001b[0;32m-> 1177\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgen_math_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgen_math_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1178\u001b[0m   \u001b[0;32massert\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_dtype\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_dtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\" vs. \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/gen_math_ops.py\u001b[0m in \u001b[0;36mmul\u001b[0;34m(x, y, name)\u001b[0m\n\u001b[1;32m   6699\u001b[0m   \u001b[0;31m# Add nodes to the TensorFlow graph.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6700\u001b[0m   _, _, _op = _op_def_lib._apply_op_helper(\n\u001b[0;32m-> 6701\u001b[0;31m         \"Mul\", x=x, y=y, name=name)\n\u001b[0m\u001b[1;32m   6702\u001b[0m   \u001b[0m_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6703\u001b[0m   \u001b[0m_inputs_flat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/op_def_library.py\u001b[0m in \u001b[0;36m_apply_op_helper\u001b[0;34m(self, op_type_name, name, **keywords)\u001b[0m\n\u001b[1;32m    791\u001b[0m         op = g.create_op(op_type_name, inputs, dtypes=None, name=scope,\n\u001b[1;32m    792\u001b[0m                          \u001b[0minput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattr_protos\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 793\u001b[0;31m                          op_def=op_def)\n\u001b[0m\u001b[1;32m    794\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0moutput_structure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop_def\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_stateful\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    795\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/func_graph.py\u001b[0m in \u001b[0;36mcreate_op\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    542\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mctxt\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctxt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"AddValue\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m         \u001b[0minp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mctxt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAddValue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 544\u001b[0;31m       \u001b[0minp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcapture\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    545\u001b[0m       \u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m     return super(FuncGraph, self)._create_op_internal(  # pylint: disable=protected-access\n",
      "\u001b[0;32m~usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/while_v2.py\u001b[0m in \u001b[0;36mcapture\u001b[0;34m(self, tensor, name, whitelisted)\u001b[0m\n\u001b[1;32m    918\u001b[0m                        \u001b[0;34m\"forward graph but in %s.\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m                        (str(tensor), _graph_name(tensor.graph)))\n\u001b[0;32m--> 920\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_WhileBodyGradFuncGraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcapture\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    921\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    922\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_capture_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/func_graph.py\u001b[0m in \u001b[0;36mcapture\u001b[0;34m(self, tensor, name)\u001b[0m\n\u001b[1;32m    603\u001b[0m               % (tensor, tensor.graph, self))\n\u001b[1;32m    604\u001b[0m         \u001b[0minner_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minner_graph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mouter_graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 605\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_capture_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    606\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    607\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/while_v2.py\u001b[0m in \u001b[0;36m_capture_helper\u001b[0;34m(self, tensor, name)\u001b[0m\n\u001b[1;32m    993\u001b[0m               \u001b[0melement_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    994\u001b[0m               \u001b[0mmax_num_elements\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maximum_iterations\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 995\u001b[0;31m               name=_build_accumulator_name(tensor))\n\u001b[0m\u001b[1;32m    996\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty_tensor_lists\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    997\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/list_ops.py\u001b[0m in \u001b[0;36mempty_tensor_list\u001b[0;34m(element_shape, element_dtype, max_num_elements, name)\u001b[0m\n\u001b[1;32m     54\u001b[0m       \u001b[0melement_dtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0melement_dtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m       \u001b[0mmax_num_elements\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_num_elements\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m       name=name)\n\u001b[0m\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/gen_list_ops.py\u001b[0m in \u001b[0;36mempty_tensor_list\u001b[0;34m(element_shape, max_num_elements, element_dtype, name)\u001b[0m\n\u001b[1;32m     74\u001b[0m         \u001b[0;34m\"EmptyTensorList\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0melement_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0melement_shape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m                            \u001b[0mmax_num_elements\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_num_elements\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m                            element_dtype=element_dtype, name=name)\n\u001b[0m\u001b[1;32m     77\u001b[0m   \u001b[0m_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m   \u001b[0m_inputs_flat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/op_def_library.py\u001b[0m in \u001b[0;36m_apply_op_helper\u001b[0;34m(self, op_type_name, name, **keywords)\u001b[0m\n\u001b[1;32m    791\u001b[0m         op = g.create_op(op_type_name, inputs, dtypes=None, name=scope,\n\u001b[1;32m    792\u001b[0m                          \u001b[0minput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattr_protos\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 793\u001b[0;31m                          op_def=op_def)\n\u001b[0m\u001b[1;32m    794\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0moutput_structure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop_def\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_stateful\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    795\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/func_graph.py\u001b[0m in \u001b[0;36mcreate_op\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    546\u001b[0m     return super(FuncGraph, self)._create_op_internal(  # pylint: disable=protected-access\n\u001b[1;32m    547\u001b[0m         \u001b[0mop_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop_def\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 548\u001b[0;31m         compute_device)\n\u001b[0m\u001b[1;32m    549\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    550\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcapture\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py\u001b[0m in \u001b[0;36m_create_op_internal\u001b[0;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)\u001b[0m\n\u001b[1;32m   3427\u001b[0m           \u001b[0minput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3428\u001b[0m           \u001b[0moriginal_op\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_default_original_op\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3429\u001b[0;31m           op_def=op_def)\n\u001b[0m\u001b[1;32m   3430\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_op_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompute_device\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcompute_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3431\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, node_def, g, inputs, output_types, control_inputs, input_types, original_op, op_def)\u001b[0m\n\u001b[1;32m   1771\u001b[0m           op_def, inputs, node_def.attr)\n\u001b[1;32m   1772\u001b[0m       self._c_op = _create_c_op(self._graph, node_def, grouped_inputs,\n\u001b[0;32m-> 1773\u001b[0;31m                                 control_input_ops)\n\u001b[0m\u001b[1;32m   1774\u001b[0m     \u001b[0;31m# pylint: enable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1775\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py\u001b[0m in \u001b[0;36m_create_c_op\u001b[0;34m(graph, node_def, inputs, control_inputs)\u001b[0m\n\u001b[1;32m   1602\u001b[0m   \u001b[0;31m# Add attrs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1603\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattr_value\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnode_def\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1604\u001b[0;31m     \u001b[0mserialized\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattr_value\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSerializeToString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1605\u001b[0m     \u001b[0;31m# TODO(skyewm): this creates and deletes a new TF_Status for every attr.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1606\u001b[0m     \u001b[0;31m# It might be worth creating a convenient way to re-use the same status.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "@tf.function\n",
    "def train_step(inp, targ, enc_hidden):\n",
    "    loss = 0\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        enc_output, enc_hidden = encoder(inp, enc_hidden)\n",
    "\n",
    "        dec_hidden = enc_hidden\n",
    "\n",
    "        dec_input = tf.expand_dims([targ_lang.word_index['<start>']] * BATCH_SIZE, 1)\n",
    "\n",
    "        # Teacher forcing - feeding the target as the next input\n",
    "        for t in range(1, targ.shape[1]):\n",
    "            # passing enc_output to the decoder\n",
    "            predictions, dec_hidden, _ = decoder(dec_input, dec_hidden, enc_output)\n",
    "\n",
    "            loss += loss_function(targ[:, t], predictions)\n",
    "\n",
    "            # using teacher forcing\n",
    "            dec_input = tf.expand_dims(targ[:, t], 1)\n",
    "\n",
    "    batch_loss = (loss / int(targ.shape[1]))\n",
    "\n",
    "    variables = encoder.trainable_variables + decoder.trainable_variables\n",
    "    gradients = tape.gradient(loss, variables)\n",
    "    \n",
    "    optimizer.apply_gradients(zip(gradients, variables))\n",
    "\n",
    "    return batch_loss\n",
    "\n",
    "\n",
    "EPOCHS = 10\n",
    "# hack\n",
    "for _ in [1]:\n",
    "    for epoch in range(EPOCHS):\n",
    "        start = time.time()\n",
    "\n",
    "        enc_hidden = encoder.initialize_hidden_state()\n",
    "        total_loss = 0\n",
    "\n",
    "        for (batch, (inp, targ)) in enumerate(dataset.shuffle(BUFFER_SIZE).take(steps_per_epoch)):\n",
    "            batch_loss = train_step(inp, targ, enc_hidden)\n",
    "            total_loss += batch_loss\n",
    "\n",
    "            if batch % 100 == 0:\n",
    "                print('Epoch {} Batch {} Loss {:.4f}'.format(epoch + 1,\n",
    "                                                     batch,\n",
    "                                                     batch_loss.numpy()))\n",
    "        # saving (checkpoint) the model every 2 epochs\n",
    "        if (epoch + 1) % 2 == 0:\n",
    "            checkpoint.save(file_prefix = checkpoint_prefix)\n",
    "\n",
    "        print('Epoch {} Loss {:.4f}'.format(epoch + 1,\n",
    "                                            total_loss / steps_per_epoch))\n",
    "        print('Time taken for 1 epoch {} sec\\n'.format(time.time() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: <start> hace mucho frio aqui . <end>\n",
      "Predicted translation: it s very cold here . <end> \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def evaluate(sentence):\n",
    "    attention_plot = np.zeros((max_length_targ, max_length_inp))\n",
    "\n",
    "    sentence = preprocess_sentence(sentence)\n",
    "\n",
    "    inputs = [inp_lang.word_index[i] for i in sentence.split(' ')]\n",
    "    inputs = tf.keras.preprocessing.sequence.pad_sequences([inputs],\n",
    "                                                           maxlen=max_length_inp,\n",
    "                                                           padding='post')\n",
    "    inputs = tf.convert_to_tensor(inputs)\n",
    "\n",
    "    result = ''\n",
    "\n",
    "    hidden = [tf.zeros((1, units))]\n",
    "    enc_out, enc_hidden = encoder(inputs, hidden)\n",
    "\n",
    "    dec_hidden = enc_hidden\n",
    "    dec_input = tf.expand_dims([targ_lang.word_index['<start>']], 0)\n",
    "\n",
    "    for t in range(max_length_targ):\n",
    "        predictions, dec_hidden, attention_weights = decoder(dec_input,\n",
    "                                                             dec_hidden,\n",
    "                                                             enc_out)\n",
    "\n",
    "        # storing the attention weights to plot later on\n",
    "        attention_weights = tf.reshape(attention_weights, (-1, ))\n",
    "        attention_plot[t] = attention_weights.numpy()\n",
    "\n",
    "        predicted_id = tf.argmax(predictions[0]).numpy()\n",
    "\n",
    "        result += targ_lang.index_word[predicted_id] + ' '\n",
    "\n",
    "        if targ_lang.index_word[predicted_id] == '<end>':\n",
    "            return result, sentence, attention_plot\n",
    "\n",
    "        # the predicted ID is fed back into the model\n",
    "        dec_input = tf.expand_dims([predicted_id], 0)\n",
    "\n",
    "    return result, sentence, attention_plot\n",
    "\n",
    "# function for plotting the attention weights\n",
    "def plot_attention(attention, sentence, predicted_sentence):\n",
    "    fig = plt.figure(figsize=(10,10))\n",
    "    ax = fig.add_subplot(1, 1, 1)\n",
    "    ax.matshow(attention, cmap='viridis')\n",
    "\n",
    "    fontdict = {'fontsize': 14}\n",
    "\n",
    "    ax.set_xticklabels([''] + sentence, fontdict=fontdict, rotation=90)\n",
    "    ax.set_yticklabels([''] + predicted_sentence, fontdict=fontdict)\n",
    "\n",
    "    ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "    ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    \n",
    "def translate(sentence):\n",
    "    result, sentence, attention_plot = evaluate(sentence)\n",
    "\n",
    "    print('Input: %s' % (sentence))\n",
    "    print('Predicted translation: {}'.format(result))\n",
    "\n",
    "    attention_plot = attention_plot[:len(result.split(' ')), :len(sentence.split(' '))]\n",
    "    plot_attention(attention_plot, sentence.split(' '), result.split(' '))\n",
    "\n",
    "    \n",
    "\n",
    "# restoring the latest checkpoint in checkpoint_dir\n",
    "checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))\n",
    "\n",
    "translate(u'hace mucho frio aqui.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: <start> ¿ todavia estan en casa ? <end>\n",
      "Predicted translation: are you still at home ? <end> \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "translate(u'¿todavia estan en casa?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: <start> universidad de colombia <end>\n",
      "Predicted translation: dance at first . <end> \n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgwAAAKKCAYAAABRbwPKAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nO3dd7xtd13n//cnuVxCEgQp0oYgRZrUEDSIIEXpKIMMgkNXgqgDM4rMMIpBFBAJCii/nwkqHRsMAqIwVCnSi7QgLQFDDS2kAGmf+WPtS04OJ/necu5Zd+/zfD4e55F91tpn38/Zj5tzX2fV6u4AAFycg+YeAAA48AkGAGBIMAAAQ4IBABgSDADAkGAAAIYEAwAwJBgAgCHBAAAMCQYAYGjH3APA3Krq/CS7dY307j54P48DcEASDJDcNxcEw5WSPDHJy5O8Y7HsVknuleTYrR8N4MBQbj4FF6iqVyZ5VXc/Z93yhye5V3fffZ7JAOYlGGCNqjojyc26+1Prll8nyb9192HzTAYwLwc9woV9Ncl9Nlh+nySnbvEsAAcMxzDAhf1ukudW1e1zwTEMRyf56SS/NNtUADOzSwLWqaofT/KoJDdYLDoxybO6+13zTQUwL8EAAAzZJQEXoaqunGTn2mXd/bmZxgGYlWCANarqMkmelenaDDs3eIoLNwHbkrMk4MKOS3LTTBdq+k6SX0zyW0lOSfILM84FMCvHMMAaVXVKkvt391ur6ltJjuzuT1XV/ZM8rLt/ZuYRAWZhCwNc2GWTfHbx+LQkl188fkeSn5hlIoADgGCAC/t0kmstHp+Y5H5VVUnuneTrs00FMDPBABf2vCQ3WTz+wySPSHJ2kqcleepMMwHMzjEMcDGq6ogkRyX5ZHd/eO55AOYiGACAIddhYNurqt/d3ed29xP35yywP1TVDya5a5Ij8v0XI/N3mt1iCwPbXlWt39VwjSSHJvnC4vOrJjkrycndfZPAEqmqo5O8Osl3k1wxyeeTXGXxub/T7DYHPbLtdfeNd30k+eMk70tyre4+oruPyHTWxHuSPGPOOWEvPS3Ji5NcLdPFyO6QaUvDe+NAXvaALQywRlWdlORe3f1v65bfLMkruvsa80wGe6eqTktyy+7+RFV9M8mtuvvEqrplkpd094/MPCJLwhYGuLArJbnUBssPSXKFLZ4FNsPZax5/OdMutyQ5I9PuNtgtggEu7HVJnlNVR1fVwVV10GIf8PGLdbBs3p/klovHb07yB1X14Ew3WfvQXEOxfOySgDWq6opJnp/kLknOWyw+KMlrkzy4u0+dazbYG1V1VJJLd/ebFn+/X5Dk1kk+keShri/C7hIMsIGqum6S6y8+/Xh3f2LOeQDmJhgAgCEXbloyVfUjmfanP9qmxM1RVc9K8rjuPnPx+CJ196O2aCzYa1X1oSQ/1d3fWFxn5CJ/M3QdBnaXYFg+D05yuyQPS/I/5h1lZdw4ySXWPL4oNsexLF6W6cJMSfLSOQdhddglsUQWt1k+OdPR+vdMctXuPu9ivwgANoHTKpfL7ZJcOsmjkpyb5G6zTrNNVNV1quqQueeAfVFV166qeyw+rj33PCwfwbBcHpzkpd19VpK/WXzOJqqqJy/OUU9NXpfp9LMvLq7HAEulqi5fVf+Q5JNJ/mHx8YmqekVVXX7e6VgmgmFJVNVhSe6d5IWLRS9Mcvequux8U62k/5rk3xeP75rkZkmOznTu+lPmGgr2wV8kuU6S22S6YukhSW6b5JpJnjPjXCwZwbA8fj7JV7v7rUnS3R/M9BvD/WadavVcKckpi8d3S/J33f3uJH+a5OazTQV7785JHt7db+/ucxcfb0/yiMU6NllVHVZVD6qqy8w9y2YSDMvjgUletG7Zi5I8ZOtHWWlfywXX2r9TkjcsHu9IUrNMBPvm1CRnbrD8rEx/39l8903y3Ew/t1eGYFgCVXX1JLfPBbsjdnlJkqMWVyVkc7wsyUsWxy5cLtMloZNp18SnZpsK9t4Tkzyjqq62a8Hi8dMX69h8D8q0a/MhM8+xqZxWCWtU1Y5MZ6FcI8nzuvsDi+X/I8np3f0Xc84Hu2ODizVdM9OxC59ffH61JN9JcpILN22uqvrhTAdK/1iSdyY5srs/NudMm8WFm5ZEVR2R5D96g8KrqiO6+3MzjLVSquoSSZ6U5Nnd/dm167r7T+aZCvaKizXN54FJ3trdH6yqf8p0Ntv/nHmmTWELw5KoqvOSXKW7v7Ju+eWTfKW7D55nstVSVWckuVF3nzz3LMDyqapPJnlSdz+vqn4+yTOTXH2jX/aWjWMYlkdl40sTH55p0yKb47VJ7jD3ELA/VNUhVXXo2o+5Z1olVfUTSa6SC7bwvCrJoUl+erahNpFdEge4NTdD6iRPqaqz1qw+ONN+sg9u+WCr6w1JnlxVN0nyvqw7ury7/88sU8FeqqprJHlWpgOnD9vgKbZObp4HJ3lFd5+RJN19dlX9XaaDH18352CbwS6JA1xVvWnx8KeSvCPJ2WtWn53p3hLHdfcnt3i0lVRV51/M6rbrh2VTVW/NdMDjnyX5ctZtqezu1270deyZqrpkki8luX93v2bN8p/MtOXySrtCYlkJhiWwuOnU3yV5WHefPvc8wPJYHJdzy+4+ce5ZVllVXSHTxd5e1N3nr1v3gCSv7+4vzTLcJhEMS6CqDs50nMJNV+X0HGBrVNXbkzyuu98y9ywsNwc9LoHFLaw/m2Tn3LOsusUNp361qj5aVWdV1bUWy/9XVd137vlgLxyT5Niq+rnFHSuPWPsx93AsDwc9Lo/fT/KHVfWA7v7q3MOssEcneWySpyb5wzXLP5/k1zPtGoJlclCme6S8PBc+fmHXmVeOy9kHVXVSNj6D7ft097X28zj7lWBYHo/JdLW2z1fVKfn+o/ddrW1z/EqmG/W8uqr+YM3y9yf50Zlmgn3x/CRfyXTxoO876JF99mdrHh+e5DeSvDvTQepJcqtMZ7M9fYvn2nSCYXm4ctvWuEaSj2yw/Jwkl9riWWAzXD/Jzbr7E3MPsoq6+3shUFXPS/LU7n7y2udU1eOyAr9wCIYl0d2/N/cM28RnkhyZ6ZiRte6WxAGnLKN3Z9o6KRj2v3tn+vmx3t8nedwWz7LpBANc2HFJ/mxxBbxKcquqemCm4xoeNutksHf+/0x3q3x6kg9n2lr2Pd39/lmmWk1nJrldvv/OtrfLdDvxpea0yiVRVTuT/HaS+yc5Iskl1q53QaHNU1UPT/I7Sa6+WPSFJMd291/ONxXsHRcj2zpV9dhMB6g/N9OdKpPk6ExXgHxCdz91rtk2g2BYElX11CS/kOQpSf4k0z9oP5zkfkke393HzzfdalpciOWg9Tf8gmWyuDT0RVp/Z1b2zeL060cnucFi0YlJntndS3+GlWBYEotTdx7Z3a+pqtMzHcT06ap6ZJI7dvd9Zh5xJVTVM5K8sLvfN/csAAcSF25aHlfKBQfdnZHksovHr0lyp1kmWk0/luQ9VXViVf12Vf3wzPPAPquqm1TVC6rqvVX1nqp6flXdaO65VllVXbaqLrf2Y+6Z9pVgWB6fS3LVxeNPJbnz4vGtknx7lolWUHf/RJLrJHlxkv+a5NNV9baq+pWq+sF5p4M9V1U/m+k6IldP8s+Zfsk4IskHquqec862aqrqGlX1z1X17SRfS3Lq4uOri/8uNbsklkRVPSXJGd39pKq6T5K/TnJKkqsleVp3//asA66oqjoyyS9mOlbk8t3tWgwslar6UJKXd/ex65Y/McnPdfdN55ls9VTVGzNt/T0u08HS6+8M+i9zzLVZBMOSqqofT3LrJJ/o7n+ce55VtXifH5DpgNNDu/vwmUeCPVJV30lyo+7+1LrlP5Lkw919yDyTrZ7FnUGP7u6NLv629OySWBJVdduq+t51M7r7Xd39x0leU1W3nXG0lVNV162q36uqTyZ5a5LrJvnNTMeRwLL5SpJbbLD8FpkuFc3mOSnJJeceYn9x4abl8aYkV8n0P/9al1mscy71Jqiq9ya5eZIPJvn/kvz1st/Dnm3vOUmOr6rrJPnXxbJbZ7o/zdNmm2o1PTrJU6rqV9dv0VkFdkksicXFV67U3aeuW37dJO/t7h+YZ7LVUlVPSvKi7j5x7llgM1RVJfnvmbaS7Tpw+guZYuFZ7R+BTbM45f2SmX6B+26Sc9euX/af04LhAFdVr1w8vHuS12f6S7jLwUlulOTE7r7LVs8GLJequnSSdPfpc8+yiqrqwRe3vrufv1Wz7A92SRz4vrb4byX5Ri58CuXZSd6WaZMje6mqnpXkcd195uLxReruR23RWLDphML+texBMCIYDnDd/dAkqaqTkxzX3WfOO9FKunEuuDfHjS/meTbHsRSq6sPZzb+v3X2T/TzOtlJVV0rywCTXznTZ/q9W1a2TfKG7T5p3un1jl8SSqKqDkqS7z198fuUk90jyse7+14v7WmB7qapjx8+adPfv7c9ZtpOqukWSN2Q6W+JHk1y/uz9TVU9Ict3u/sU559tXgmFJVNU/J3lNdz+zqg5P8vEkhyU5PMkvdfcLZh0Q9lBV3TjJIzL9Jvaw7v5iVd0ryWe7+wPzTgd7rqrelOQt3X3s4gDImy6C4VZJ/qa7L/ZGYAc6uySWx1FJHrt4fO8k30pyzUyXL35MEsGwSarqF5LcMckPZd21Srr7Z2cZasVU1Z2SvDLTpYrvkGTXFTSvneQhSe41z2Srq6quleSGmXZVnNjdn5l5pFV0iyS/tMHyL2YFruPiwk3L4/Ak31w8vlOmS72ek+SNmX7Isgmq6mlJXpTp1uHfzHTQ6doPNsfvJ/mN7v7PmQ7e3eXNmW4Axiapqh+oqr/PdA+af0jyiiSfrKq/23XWBJvm20k2uufM9fP919BZOrYwLI/PJbl1Vb0q042n/sti+eWSnDXbVKvnQUnu390vnXuQFXejJP+0wfKvZ/o7zeZ5ZpKbJLl9Lnzhpj9P8oxs/Bsxe+cVSY6tql0/n3txx9unJnnZXENtFlsYlscfJ3lhphtOfT7JWxbLb5vkw3MNtYIOynSVR/avr2e6cdp6R2b6O87m+dkkv9zd/9Ld5yw+3pzkmNj1s9kekyl4T01yaKbT3j+V5LQkvzPjXJvCFoYl0d3HLy5bfESS1+06WyLJp5M8fr7JVs4JmW429YSZ51h1L0nytKq6b6Z96juq6qcy3eXvubNOtnoulY13p309iRtPbaLu/laSn6yqO2SK34OSvL+7Xz/vZJvDWRJLoKouk+Qm3f3WDdbdOtOpld/Y+slWT1U9O9PtrD+W5ENJzlm73oWbNkdVXSLJ8zLdNrySnJ/ph+uLkzyku8+bb7rVUlWvy3SQ9AO7+6zFssMyHSj9A939M3POtyq2w89pwbAEFgcmfTHJnbv77WuW3zTJu5Ncrbu/Otd8q2RxWtRF6u7bb9Us28HiyP1dv4l9oLs/OfNIK2dx+uprMm0i/9Bi8Y0zHaB3p+7+6FyzrZLt8HNaMCyJqnpxkjO6+xFrlh2X6WIgTvXjgFdVf7W7z+3uh+3PWbabqjo00ynY118sOjHJi7v72xf9VeypVf85LRiWRFXdOclfJ7lyd5+9uPLjKUl+vbv/z7zTrY41N/vaSHf3z23ZMCtmcYbPWrfNtCti10G7N8q0peEtq/DD9UCxuAPrf3T3n69b/iuZfut1DNQmWfWf086SWB6vy7QJ8R6Lz++YZGeS9T+E2Tfrr7uw6wJZt43rMOyT7r7nro9Mp/e9Nsl/6u7bdvdtk1w906bzd8055wp6YJKNrpz5/kynEbN5VvrntC0MS6Sqnprket19r6p6QZLTu/vX5p5rO6iqpyf5luvub46q+mKSO3b3x9Yt/9Ekb+juK88z2eqpqu8kueH6Kzsujh/5WHc7U2ITrfLPaVsYlssLktylqo5I8p+TrPStVA8wxydZif/pDxCHJ7nqBsuvkungPDbP55LcZoPlt41rXuwPK/tz2nUYlkh3f7SqPpLp1LNTuvvdc8+0jVxv7gFWzMuSPLeqfivJOxfLjs50Rbyl39d7gDk+yZ9U1c5Ml5JPpk3lT8n0frOJVvnntGBYPi/IdDnX3557kFVUVc9avyjTb713TbLbR/kz9MgkT890LYZLLJadm+QvM10tj03S3U+vqiskeVam/enJdP+OZ3b3H8032UpbyZ/TjmFYMlV1uST/Lcnx3f2luedZNRtch+H8TJd5fWOSv+ruc7d+qtW1uIDQrpunfbq7z5xznlW2eK9vuPj0xO4+Y855Vtmq/pwWDADAkIMeAYAhwQAADAmGJVRVx8w9w3bhvd463uut4X3eOqv2XguG5bRSfwkPcN7rreO93hre562zUu+1YAAAhrb9WRI7DzqkL3XQ4XOPsUfOPv872XnQcl3N9ewrXmruEfbKuWedmR2HHjb3GHtkx7eX8//pc84+M5fYuVzv9TJaxvf5oO+eN/cIe+Xs887KzoOX68Kl3/rOl77a3VfcaN22v3DTpQ46PLc63A0I97fPPeRGc4+wbVzhw+fMPQJsqkNPPm3uEbaN1370yZ+9qHV2SQAAQ4IBABgSDADAkGAAAIYEAwAwJBgAgCHBAAAMCQYAYEgwAABDggEAGBIMAMCQYAAAhgQDADAkGACAIcEAAAwJBgBgSDAAAEOCAQAYEgwAwJBgAACGBAMAMCQYAIAhwQAADAkGAGBIMAAAQ4IBABgSDADAkGAAAIYEAwAwJBgAgCHBAAAMCQYAYEgwAABDggEAGBIMAMCQYAAAhgQDADAkGACAof0SDFX1j1X1vP3x2gDA1rOFAQAYEgwAwNA+B0NVHVpVz6uqM6rqy1X1v9etf0BVvaeqTq+qr1TV31fV1dasv11VdVXdsareVVVnVdV7q+rIda9zdFW9sarOrKrTFo+vulhXVfXYqvp0VX27qj5cVQ/Y1+8NAJhsxhaG45L8TJKfT3LHJDdPcts163cmOTbJTZPcI8kVkvz1Bq/zlCT/K8mRSb6W5MVVVUlSVTdN8qYkn0py6yRHJ/nbJDsWX/sHSX4pya8lueHitY6vqrtvwvcHANvejvFTLlpVHZ7pH+qHdfdrF8semuSUXc/p7r9a8yWfqapHJjmxqv5Td5+yZt3ju/tNi9d4YpK3Jbna4rUem+SD3X3MmuefuHjuYUl+I8mduvuti3UnVdWPZQqIV28w9zFJjkmSQ+qwvf32AWDb2KdgSHLtTFsQ3rFrQXefUVUf3vX5YtfCsUluluRySWqx6oisCYskH1rz+AuL//7Q4jk3T/Lyi5jhhkkOSfKaquo1yy+R5OSNvqC7T0hyQpJcZscVeqPnAAAX2NdguFiL3/5fm+T1SR6Y5CuZdkm8NVNorHXOmse7/hHfnV0mu55zzySfu5jXBAD20r4Gw6cz/aN8dJLPJN+LhBst1l0/UyD87+4+abH+3nvx53wgyR0uYt3Hknw3yTW6+4178doAwMA+BcNi98NfJnlqVZ2aaVfC7yY5ePGUz2X6x/zXq+rZSW6Q5Pf34o96WpJ3VtUJSZ6d5DtJbpPk/3b356rquCTHLQ6SfEuSwzNFzPmL3Q8AwD7YjLMkHpPpDIaXL/77kUz/aKe7T03y4CT3yrQl4NhMByjuke7+YJKfzrTF4p1J3pXkfrlgl8PjkzxhMctHk7wu01kbJ+3dtwQArLXPxzB095lJHrT42Gj932Y6BXKtWrP+zWs/Xyw7eYNlb8uFT9dcu66T/OniAwDYZK70CAAMCQYAYEgwAABDggEAGBIMAMCQYAAAhgQDADAkGACAIcEAAAwJBgBgSDAAAEOCAQAYEgwAwJBgAACGBAMAMCQYAIAhwQAADAkGAGBIMAAAQ4IBABgSDADAkGAAAIYEAwAwJBgAgCHBAAAMCQYAYEgwAABDggEAGBIMAMCQYAAAhgQDADAkGACAIcEAAAwJBgBgSDAAAEOCAQAYEgwAwNCOuQeYW593fs47/fS5x1h5V//nr889wrZxxrUvM/cI28Ypdz9v7hG2hRv8kff5QGALAwAwJBgAgCHBAAAMCQYAYEgwAABDggEAGBIMAMCQYAAAhgQDADAkGACAIcEAAAwJBgBgSDAAAEOCAQAYEgwAwJBgAACGBAMAMCQYAIAhwQAADAkGAGBIMAAAQ4IBABgSDADAkGAAAIYEAwAwJBgAgCHBAAAMCQYAYEgwAABDggEAGBIMAMCQYAAAhgQDADAkGACAIcEAAAwJBgBgSDAAAEOCAQAYEgwAwJBgAACGBAMAMCQYAIChlQuGqvrhquqqOmruWQBgVaxcMAAAm28pg6Gq7lJVb62qb1TV16vqtVV1g8Xqkxb/fc9iS8ObZxoTAFbGUgZDksOSPCPJjyW5XZLTkryqqnYuliXJXZJcJcm95xgQAFbJjrkH2Bvd/bK1n1fVQ5N8K1MsnLJY/LXu/tJGX19VxyQ5JkkOyaH7cVIAWA1LuYWhqq5dVS+pqk9X1beSfDnT93LE7nx9d5/Q3Ud191GXyCX366wAsAqWcgtDkn/MtCXhEUk+n+TcJB9LsnPOoQBgVS1dMFTV5ZNcP8mvdvebFsuOzAXfy9mL/x48w3gAsJKWLhiSfCPJV5M8vKr+I8nVkjwt01aGJPlKkm8nuXNVnZzkO9192hyDAsCqWLpjGLr7/CS/kOQmST6S5NlJHp/ku4v15yZ5VJJfTvKFJK+YZ1IAWB3LuIUh3f3GJDdat/jwNev/IslfbOlQALDClm4LAwCw9QQDADAkGACAIcEAAAwJBgBgSDAAAEOCAQAYEgwAwJBgAACGBAMAMCQYAIAhwQAADAkGAGBIMAAAQ4IBABgSDADAkGAAAIYEAwAwJBgAgCHBAAAMCQYAYEgwAABDggEAGBIMAMCQYAAAhgQDADAkGACAIcEAAAwJBgBgSDAAAEOCAQAYEgwAwJBgAACGBAMAMCQYAIAhwQAADAkGAGBox9wDzK0OOigHHXro3GOsvD7xM3OPsG0c/gm/B2yVy13x5nOPsC186bht/0/V1rnnRa/ykwUAGBIMAMCQYAAAhgQDADAkGACAIcEAAAwJBgBgSDAAAEOCAQAYEgwAwJBgAACGBAMAMCQYAIAhwQAADAkGAGBIMAAAQ4IBABgSDADAkGAAAIYEAwAwJBgAgCHBAAAMCQYAYEgwAABDggEAGBIMAMCQYAAAhgQDADAkGACAIcEAAAwJBgBgSDAAAEOCAQAYEgwAwJBgAACGBAMAMCQYAIAhwQAADAkGAGBIMAAAQ7MGQ1UdVFXHV9XXqqqr6uSq+sc5ZwIAvt+Omf/8uyV5aJLbJflMkm8nqX15wap6XpIrdPc99nU4AGAydzBcJ8kXu/tfd+fJVbWzu8/ezzMBAOvMFgyLLQEPXjzuJJ9N8uas2TpQVW9OcmKSMxfPPTnJLavqEUl+M8kRSc5I8r4kd0/yO+teM0lu391v3v/fEQCsrjm3MDw6UyQ8LMktk5yX5GkbPO8BSU5IcpskVVVHJXl2pjB4W5LLJrnD4rnHJblBkssleeBi2df30/wAsG3MFgzdfVpVnZ7kvO7+UpJUbXj4wknd/Zu7Pqmqe2fa4vDK7j49U3T822L1GVX17STf3fWaG6mqY5IckySH1GGb8e0AwEpbhtMq37fu89dlioSTqurFVfXgqrr0nrxgd5/Q3Ud191E765BNGxQAVtUyBMOZaz9ZbFU4Msl9k3wuyeOSfLyqrjrDbACwLSxDMHyf7j63u9/Y3Y9LcpMkhyXZdRrl2UkOnm04AFhBc59Wuceq6h5Jrp3kLZkOaLx9kktnOpsimc6kuGtVXS/J15Kc1t3nzDAqAKyMZdzC8M0k90ry+iQfT/KYJL/c3W9drH9Opnh4b5JTk9x6jiEBYJXMuoWhu4/LdCrkrs8fsm797Tb4mrdl2qpwUa95apI7bdqQAMBSbmEAALaYYAAAhgQDADAkGACAIcEAAAwJBgBgSDAAAEOCAQAYEgwAwJBgAACGBAMAMCQYAIAhwQAADAkGAGBIMAAAQ4IBABgSDADAkGAAAIYEAwAwJBgAgCHBAAAMCQYAYEgwAABDggEAGBIMAMCQYAAAhgQDADAkGACAIcEAAAwJBgBgSDAAAEOCAQAYEgwAwJBgAACGBAMAMCQYAIAhwQAADAkGAGBox9wDzK47Oe+8uadYebXzEnOPsH34+7xlrvy6L8w9wrbw6ie8Yu4Rto2DL2adLQwAwJBgAACGBAMAMCQYAIAhwQAADAkGAGBIMAAAQ4IBABgSDADAkGAAAIYEAwAwJBgAgCHBAAAMCQYAYEgwAABDggEAGBIMAMCQYAAAhgQDADAkGACAIcEAAAwJBgBgSDAAAEOCAQAYEgwAwJBgAACGBAMAMCQYAIAhwQAADAkGAGBIMAAAQ4IBABgSDADAkGAAAIYEAwAwJBgAgCHBAAAMCQYAYEgwAABDggEAGBIMAMCQYAAAhgQDADAkGACAIcEAAAztmHuAOVTVMUmOSZJD6rCZpwGAA9+23MLQ3Sd091HdfdTOXHLucQDggLctgwEA2DOCAQAYWtlgqKpfr6qPzz0HAKyClQ2GJFdIcr25hwCAVbCywdDdT+jumnsOAFgFKxsMAMDmEQwAwJBgAACGBAMAMCQYAIAhwQAADAkGAGBIMAAAQ4IBABgSDADAkGAAAIYEAwAwJBgAgCHBAAAMCQYAYEgwAABDggEAGBIMAMCQYAAAhgQDADAkGACAIcEAAAwJBgBgSDAAAEOCAQAYEgwAwJBgAACGBAMAMCQYAIAhwQAADAkGAGBIMAAAQ4IBABgSDADAkGAAAIYEAwAwJBgAgKEdcw8wux07ctDlLzf3FCvv/G+eNvcI20Zd6lJzj7BtnP/lU+ceYVu484n3mHuEbeQZF7nGFgYAYEgwAABDggEAGBIMAMCQYAAAhgQDADAkGACAIcEAAAwJBgBgSDAAAEOCAQAYEgwAwJBgAACGBAMAMCQYAIAhwQAADAkGAGBIMAAAQ4IBABgSDADAkGAAAIYEAwAwJBgAgCHBAAAMCQYAYEgwAABDggEAGBIMAMCQYAAAhgQDADAkGACAIcEAAAwJBgBgSDAAAEOCAQAYEgwAwJBgAACGBAMAMCQYAIAhwZFklhAAAAZRSURBVAAADAkGAGBoaYKhqh5TVSfPPQcAbEdLEwwAwHw2JRiq6geq6rKb8Vp78GdesaoO2co/EwC2q70Ohqo6uKruXFUvSfKlJDddLL9MVZ1QVV+pqtOr6l+q6qg1X/eQqjqjqu5YVR+pqjOr6k1Vdc11r//YqvrS4rkvSHL4uhHuluRLiz/r1nv7fQAAY3scDFX1o1X1R0n+I8nfJjkzyV2SvKWqKsmrk1wtyT2S3DzJW5K8saqusuZlLpnkcUkeluRWSS6b5M/X/Bn3TfIHSY5NcmSSf0/yG+tGeXGSX0xy6SSvq6pPVdXvrg+Pi/gejqmq91bVe88+/9t7+hYAwLazW8FQVZevqkdV1fuSfCDJ9ZM8OsmVu/vh3f2W7u4kt09ysyT36e53d/enuvvxST6T5IFrXnJHkl9bPOdDSY5LcrtFcCTJf0/y/O4+vrs/0d1PSvLutTN197nd/U/dff8kV07y5MWf/8mqenNVPayq1m+V2PW1J3T3Ud191M6DLrU7bwEAbGu7u4XhvyV5ZpLvJLlud/9sd/99d39n3fNukeTQJKcudiWcUVVnJLlRkmuved53u/vf13z+hSQ7k/zg4vMbJHnHutde//n3dPe3uvuvuvv2SW6Z5EpJ/jLJfXbz+wMALsaO3XzeCUnOSfKgJB+pqpcneWGSN3T3eWued1CSLye5zQav8a01j89dt67XfP0eq6pLZtoF8oBMxzZ8NNNWilfszesBABe2W/9Ad/cXuvtJ3X29JD+d5Iwkf5PklKp6elXdbPHU92f67f78xe6ItR9f2YO5Tkxy9LplF/q8Jj9ZVcdnOujyT5N8KsktuvvI7n5md39jD/5MAOAi7PFv9N39zu5+ZJKrZNpVcd0k76mq2yR5fZK3J3lFVd21qq5ZVbeqqt9brN9dz0zy4Kp6eFX9SFU9LsmPr3vOA5L83yQ/kOT+Sa7e3b/V3R/Z0+8JALh4u7tL4vt093eTvDTJS6vqh5Kc191dVXfLdIbDc5L8UKZdFG9P8oI9eO2/raprJXlSpmMiXpnkj5M8ZM3T3pDpoMtvff8rAACbqaaTG7avy+y8Uv/Ele439xgr7/xvnjb3CNtG7dw59wjbRn/3u3OPsC2c/6rLzT3CtvH6Ozzjfd191EbrXBoaABgSDADAkGAAAIYEAwAwJBgAgCHBAAAMCQYAYEgwAABDggEAGBIMAMCQYAAAhgQDADAkGACAIcEAAAwJBgBgSDAAAEOCAQAYEgwAwJBgAACGBAMAMCQYAIAhwQAADAkGAGBIMAAAQ4IBABgSDADAkGAAAIYEAwAwJBgAgCHBAAAMCQYAYEgwAABDggEAGBIMAMCQYAAAhgQDADAkGACAoR1zDzC3PuecnPv5L8w9BmyeM8+cewLYXHc8a+4JiC0MAMBuEAwAwJBgAACGBAMAMCQYAIAhwQAADAkGAGBIMAAAQ4IBABgSDADAkGAAAIYEAwAwJBgAgCHBAAAMCQYAYEgwAABDggEAGBIMAMCQYAAAhgQDADAkGACAIcEAAAwJBgBgSDAAAEOCAQAYEgwAwJBgAACGBAMAMCQYAIAhwQAADAkGAGBIMAAAQ4IBABgSDADAkGAAAIYEAwAwJBgAgCHBAAAMCQYAYEgwAABDggEAGBIMAMCQYAAAhgQDADAkGACAoR1zDzCHqjomyTFJckgOnXkaADjwbcstDN19Qncf1d1HXSKXnHscADjgbctgAAD2jGAAAIYEAwAwJBgAgCHBAAAMCQYAYEgwAABDggEAGBIMAMCQYAAAhgQDADAkGACAIcEAAAwJBgBgSDAAAEOCAQAYEgwAwJBgAACGBAMAMCQYAIAhwQAADAkGAGBIMAAAQ4IBABgSDADAkGAAAIYEAwAwJBgAgCHBAAAMCQYAYEgwAABDggEAGBIMAMCQYAAAhgQDADAkGACAIcEAAAwJBgBgSDAAAEOCAQAYEgwAwJBgAACGBAMAMFTdPfcMs6qqU5N8du459tAVknx17iG2Ce/11vFebw3v89ZZxvf6Gt19xY1WbPtgWEZV9d7uPmruObYD7/XW8V5vDe/z1lm199ouCQBgSDAAAEOCYTmdMPcA24j3eut4r7eG93nrrNR77RgGAGDIFgYAYEgwAABDggEAGBIMAMCQYAAAhv4f+TjLg0u0cNEAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "translate(u'Universidad de Colombia')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
