{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import reuters\n",
    "import tensorflow as tf\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_data, train_labels), (test_data, test_labels) = reuters.load_data()\n",
    "word_indexes = reuters.get_word_index()\n",
    "\n",
    "word_indexes[\"OOV\"] = 0\n",
    "word_indexes[\"START\"] = -1\n",
    "word_indexes[\"PAD\"] = -2\n",
    "index_words = {v: k for k, v in word_indexes.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30982\n",
      "8982\n"
     ]
    }
   ],
   "source": [
    "# vocab size\n",
    "vocab_size = len(word_indexes)\n",
    "print(vocab_size)\n",
    "print(len(train_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1262329\n",
      "[(1, 27595, 28842, 8, 43, 10), (27595, 28842, 8, 43, 10, 447), (28842, 8, 43, 10, 447, 5), (8, 43, 10, 447, 5, 25), (43, 10, 447, 5, 25, 207), (10, 447, 5, 25, 207, 270), (447, 5, 25, 207, 270, 5), (5, 25, 207, 270, 5, 3095), (25, 207, 270, 5, 3095, 111), (207, 270, 5, 3095, 111, 16)]\n"
     ]
    }
   ],
   "source": [
    "window_size = 6\n",
    "\n",
    "windows = [\n",
    "    window\n",
    "    for sent in train_data\n",
    "    for window in zip(*[iter(sent[i:]) for i in range(window_size)])\n",
    "]\n",
    "\n",
    "test_windows = [\n",
    "    window\n",
    "    for sent in test_data\n",
    "    for window in zip(*[iter(sent[i:]) for i in range(window_size)])\n",
    "]\n",
    "\n",
    "print(len(windows))\n",
    "print(windows[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 27595, 28842, 8, 43)\n",
      "10\n",
      "(1, 4, 1378, 2025, 9)\n",
      "697\n"
     ]
    }
   ],
   "source": [
    "window_train = [tuple(window[:window_size - 1]) for window in windows]\n",
    "window_train_labels = [window[window_size - 1] for window in windows]\n",
    "\n",
    "window_test = [tuple(window[:window_size - 1]) for window in test_windows]\n",
    "window_test_labels = [window[window_size - 1:][0] for window in test_windows]\n",
    "\n",
    "SHUFFLE_BUFFER_SIZE = 500\n",
    "BATCH_SIZE = 32\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((window_train, window_train_labels))\\\n",
    "                    .shuffle(SHUFFLE_BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=True)\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((window_test, window_test_labels))\\\n",
    "                    .shuffle(SHUFFLE_BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=True)\n",
    "\n",
    "print(window_train[0])\n",
    "print(window_train_labels[0])\n",
    "\n",
    "print(window_test[0])\n",
    "print(window_test_labels[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['PAD', 'mcgrath', 'rentcorp', 'said', 'as']\n",
      "for\n",
      "['PAD', 'the', 'great', 'atlantic', 'and']\n",
      "how\n"
     ]
    }
   ],
   "source": [
    "print([index_words[i-3] for i in window_train[0]])\n",
    "print(index_words[window_train_labels[0]])\n",
    "print([index_words[i-3] for i in window_test[0]])\n",
    "print(index_words[window_test_labels[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            [(None, 5)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_2 (Embedding)         (None, 5, 32)        991456      input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)             (None, 160)          0           embedding_2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 10)           1610        flatten_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 170)          0           flatten_2[0][0]                  \n",
      "                                                                 dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 30982)        5297922     concatenate_2[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 6,290,988\n",
      "Trainable params: 6,290,988\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "embedding_size = 32\n",
    "\n",
    "input_layer = tf.keras.layers.Input(shape=(window_size-1,))\n",
    "embedding = tf.keras.layers.Embedding(vocab_size + 1, embedding_size)(input_layer)\n",
    "flattened = tf.keras.layers.Flatten()(embedding)\n",
    "dense_connected = tf.keras.layers.Dense(10, activation='relu')(flattened)\n",
    "concat = tf.keras.layers.Concatenate()([flattened, dense_connected])\n",
    "prediction = tf.keras.layers.Dense(vocab_size, activation='sigmoid')(concat)\n",
    "\n",
    "model = tf.keras.models.Model(inputs=[input_layer], outputs=[prediction])\n",
    "\n",
    "model.compile(\n",
    "    'adam',\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True, reduction='none'),\n",
    "    metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "39447/39447 [==============================] - 1876s 48ms/step - loss: 9.7116 - accuracy: 0.0506\n",
      "Epoch 2/10\n",
      "39447/39447 [==============================] - 1766s 45ms/step - loss: 9.7272 - accuracy: 0.0513\n",
      "Epoch 3/10\n",
      "39447/39447 [==============================] - 1769s 45ms/step - loss: 9.7235 - accuracy: 0.0515\n",
      "Epoch 4/10\n",
      "39447/39447 [==============================] - 1764s 45ms/step - loss: 9.7057 - accuracy: 0.0517\n",
      "Epoch 5/10\n",
      "39447/39447 [==============================] - 1760s 45ms/step - loss: 9.6719 - accuracy: 0.0562\n",
      "Epoch 6/10\n",
      "39447/39447 [==============================] - 1766s 45ms/step - loss: 9.6447 - accuracy: 0.0668\n",
      "Epoch 7/10\n",
      "39447/39447 [==============================] - 1764s 45ms/step - loss: 9.6304 - accuracy: 0.0734\n",
      "Epoch 8/10\n",
      "39447/39447 [==============================] - 1766s 45ms/step - loss: 9.6152 - accuracy: 0.0750\n",
      "Epoch 9/10\n",
      "39447/39447 [==============================] - 1766s 45ms/step - loss: 9.5997 - accuracy: 0.0742\n",
      "Epoch 10/10\n",
      "39447/39447 [==============================] - 1768s 45ms/step - loss: 9.5815 - accuracy: 0.0747\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f2d1c6b2e48>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_dataset, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10013/10013 [==============================] - 116s 12ms/step - loss: 9.5878 - accuracy: 0.0795\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([9.58605  , 9.581945 , 9.588014 , 9.593565 , 9.5833435, 9.587584 ,\n",
       "        9.58732  , 9.587653 , 9.588189 , 9.590981 , 9.592483 , 9.58372  ,\n",
       "        9.581615 , 9.579176 , 9.590049 , 9.592733 , 9.58757  , 9.581211 ,\n",
       "        9.595586 , 9.593242 , 9.592864 , 9.580015 , 9.591894 , 9.583114 ,\n",
       "        9.588044 , 9.586556 , 9.586377 , 9.596849 , 9.582156 , 9.585856 ,\n",
       "        9.59498  , 9.588201 ], dtype=float32), 0.07950914]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
